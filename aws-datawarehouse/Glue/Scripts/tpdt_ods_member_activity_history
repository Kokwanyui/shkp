import sys
import boto3
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from awsglue.dynamicframe import DynamicFrame
from datetime import datetime, date, time, timezone,timedelta 
from pyspark.sql.functions import *
from pyspark.sql.types import *
import pandas as pd
import numpy as np
import json
from datetime import datetime, date, time, timezone,timedelta 


args = getResolvedOptions(sys.argv, ['JOB_NAME', 'env'])
##Initialization
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)


##Input and Output Config
env = args['env']
table_name = args['JOB_NAME']
if env == 'prod':
    db01="tpdt_01replica"
    db03="tpdt_03dw"
    db02="tpdt_02replica"
    output_path="s3://tpdt-dw/"+table_name+"/"
    staging_path="s3://tpdt-staging/"
    dimension_path="s3://tpdt-dimension/"
else:
    db01="tpdt_01replica_"+env
    db03="tpdt_03dw_"+env
    output_path="s3://tpdt-dw-"+env+"/"+table_name+"/"
    staging_path="s3://tpdt-staging-"+env+"/"
    dimension_path="s3://tpdt-dimension-"+env+"/"


prefix="shkpmalls_vip_"



## Source Extraction
##source table : member 
t_member_activity_history = glueContext.create_dynamic_frame.from_catalog(database = db01, table_name = prefix+'member_activity_history', transformation_ctx = "member_activity_history")
member_activity_history_df = t_member_activity_history.toDF().withColumn("action_type_detail", when(col("action_type")==1, "Login")\
                                                          .when(col("action_type")==2, "Change Status")\
                                                          .when(col("action_type")==3, "Change Password")\
                                                          .when(col("action_type")==4, "Forget Password")\
                                                          .when(col("action_type")==5, "Verified")\
                                                          .when(col("action_type")==6, "Register")\
                                                          .when(col("action_type")==7, "Reset Password")\
                                                          .otherwise(""))\
                                                          .withColumn("ip_address", lit(""))
member_activity_history_df.createOrReplaceTempView("ods_member_activity_history")
print("Source Extraxtion Finished: Member_activity_history...")

spark.conf.set("spark.sql.session.timeZone", "UTC")


## Loading Result to S3
print("Saving Result into target destination...")

member_activity_history_df.write.format('parquet').partitionBy("action_type").mode('overwrite').option("header",True).save(output_path)

print(f"Result Saved in {output_path}...")


job.commit()