import sys
import boto3
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from awsglue.dynamicframe import DynamicFrame
from datetime import datetime, date, time, timezone, timedelta
from pyspark.sql import Row, Window
from pyspark.sql.functions import *
from pyspark.sql.types import *
import pandas as pd
import numpy as np
import json
import time

args = getResolvedOptions(sys.argv, ['JOB_NAME', 'env'])
##Initialization
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)
spark.conf.set("spark.sql.session.timeZone", "GMT+8")
spark.conf.set("spark.sql.broadcastTimeout", 7200)
spark.conf.get("spark.sql.autoBroadcastJoinThreshold")

##Input and Output Config
env = args['env']
table_name = args['JOB_NAME']
if env == 'prod':
    db01 = "tpdt_01replica"
    db03 = "tpdt_03dw"
    db02 = "tpdt_02replica"
    db03sub = "tpdt_03sub"
    db03fd = "tpdt_03foodordering"
    db03redshift = "tpdt_03redshift"
    output_path = "s3://tpdt-adhoc/" + table_name + "/"
    staging_path = "s3://tpdt-staging/"
    dimension_path = "s3://tpdt-dimension/"
    foodorder_path = "s3://tpdt-foodordering/"
    db03adhoc = "tpdt_03adhoc"
else:
    db01 = "tpdt_01replica_" + env
    db03 = "tpdt_03dw_" + env
    db03sub = "tpdt_03sub_" + env
    db03fd = "tpdt_03foodordering" + env
    output_path = "s3://tpdt-dw-" + env + "/" + table_name + "/"
    staging_path = "s3://tpdt-staging-" + env + "/"
    dimension_path = "s3://tpdt-dimension-" + env + "/"
    foodorder_path = "s3://tpdt-foodordering-" + env + "/"

dimension_prefix = "bi_dimension_"
prefix = "shkpmalls_vip_"
prefix03 = "tpdt_"
delta_date = ((datetime.today() + timedelta(hours=8)) - timedelta(days=90)).strftime('%Y-%m-%d')


## Source Extraction -----------------------------------------------------------------------------------------------------------------------------------------------------------
##source table : receipt
receipt_hashexpression = {"hashfield": "receipt_id", "hashpartitions": "20"}
t_receipt = glueContext.create_dynamic_frame.from_catalog(database=db01, table_name=prefix + 'receipt', transformation_ctx="receipt", additional_options=receipt_hashexpression)
receipt_df = t_receipt.toDF().filter(f"to_date(receipt_date) >= '{delta_date}'")
receipt_df.createOrReplaceTempView("receipt")
print("Source Extraction Finished: receipt...")

##source table : spending_transaction
spending_transaction_hashexpression = {"hashexpression": "spending_transaction_id", "hashpartitions": "20"}
t_spending_transaction = glueContext.create_dynamic_frame.from_catalog(database=db01, table_name=prefix + 'spending_transaction', transformation_ctx="spending_transaction", additional_options=spending_transaction_hashexpression)
spending_transaction_df = t_spending_transaction.toDF().filter(f"to_date(updated_date) >= '{delta_date}'")
spending_transaction_df.createOrReplaceTempView("spending_transaction")
print("Source Extraxtion Finished: spending_transaction...")

##source table : partner
t_partner = glueContext.create_dynamic_frame.from_catalog(database=db01, table_name=prefix + 'partner', transformation_ctx="partner")
partner_df = t_partner.toDF()
partner_df.createOrReplaceTempView("partner")
print("Source Extraxtion Finished: partner...")

##source table : partner_spending_transaction
t_partner_spending_transaction = glueContext.create_dynamic_frame.from_catalog(database=db01, table_name=prefix + 'partner_spending_transaction', transformation_ctx="partner_spending_transaction")
partner_spending_transaction_df = t_partner_spending_transaction.toDF().filter(f"to_date(updated_date) >= '{delta_date}'")
partner_spending_transaction_df.createOrReplaceTempView("partner_spending_transaction")
print("Source Extraxtion Finished: partner_spending_transaction...")

## mapping table : dim_tp_mall_mapping.csv
t_mall_mapping = glueContext.create_dynamic_frame.from_catalog(database=db02, table_name=dimension_prefix + 'dim_mall_mapping', transformation_ctx="dim_mall_mapping")
mall_mapping_df = t_mall_mapping.toDF()
mall_mapping_df.createOrReplaceTempView("dim_tp_mall_mapping")

# mall_mapping_df = spark.read.csv(dimension_path + 'tpdt_dim_tp_mall_mapping/tpdt_dim_tp_mall_mapping.csv', header='true', inferSchema='true', sep=',')
# mall_mapping_df.createOrReplaceTempView("dim_tp_mall_mapping")
print("Source Extraxtion Finished: dim_tp_mall_mapping.csv...")

## mapping table : dim_abnormal_log.csv
if env == 'prod':
    t_abnormal_receipt = glueContext.create_dynamic_frame.from_catalog(database=db03adhoc, table_name='abnormal_receipt', transformation_ctx="abnormal_receipt")
    abnormal_log_df1 = t_abnormal_receipt.toDF().select('type', 'value').filter("value is not null")
    abnormal_log_df = abnormal_log_df1.withColumn('value', col('value').cast(IntegerType()))
else:
    abnormal_log_df = spark.read.csv(dimension_path + 'tpdt_dim_abnormal_log/tpdt_dim_abnormal_log.csv', header='true', inferSchema='true', sep=',').filter("type = 'receipt_id'").filter('type = "receipt_id"')
abnormal_log_df.createOrReplaceTempView("dim_abnormal_log")
print("Source Extraxtion Finished: dim_abnormal_log.csv...")

##mapping table : member
t_member_staging = glueContext.create_dynamic_frame.from_catalog(database=db03sub, table_name=prefix03 + 'staging_member', transformation_ctx="staging_member")
member_df = t_member_staging.toDF()
print("Source Extraxtion Finished: member...")

##mapping table : shop
t_shop = glueContext.create_dynamic_frame.from_catalog(database=db03sub, table_name=prefix03 + 'staging_shop', transformation_ctx="staging_shop")
shop_df = t_shop.toDF().drop('team')
print("Source Extraxtion Finished: shop...")

## spending master before delta
t_spending_before_delta = glueContext.create_dynamic_frame.from_catalog(database=db03redshift, table_name=prefix03 + 'dw_dw_spending', redshift_tmp_dir="s3://tpdt-athena-queryresult", transformation_ctx="redshift_dw_spending_before_delta")
spending_before_delta_df = t_spending_before_delta.toDF().filter(f"receipt_transaction_date < '{delta_date}'") \
                                                     .drop('member_status_detail', 'registration_date', 'gender', 'age', 'age_group', 'residence', 'district', 'district_cs', 'member_tier', 'shop_name', 'lms_agreement_no', 'lms_trade_name', 'lms_standard_brand_name', 'lms_standard_trade_category', 'lms_standard_group', 'lms_charge_area')


## Source Extraction -----------------------------------------------------------------------------------------------------------------------------------------------------------


## Data Transformation -----------------------------------------------------------------------------------------------------------------------------------------------------------
spark.conf.set("spark.sql.session.timeZone", "GMT+8")
print("Perform data transformation...")

## Transformation Step 2: Extract Successful Partner Spending Transaction and Map Partner
tmp_partner_mapping = spark.sql("""
		SELECT
		 t1.result as mapping_spending_transaction_id,
		 t2.name_lang1 as partner
		from partner_spending_transaction as t1
		inner join partner as t2 on t1.partner_id = t2.partner_id
		where success = 1
""")
print("Tranformation: Partner Transaction Mapped")

## Transformation Step 5: Select columns and cleaning for receipts and spending transaction
spark.conf.set("spark.sql.session.timeZone", "GMT+8")
receipt_status_detail = {
    'A': 'Approved',
    'R': 'Rejected',
    'W': 'Waiting for Approval',
    'V': 'Invalid'
}

receipt_type_detail = {
    'B': 'Spending to Earn Point',
    'G': 'Spending to Redeem Gift',
    'S': 'Spending to Redeem Gift'
}


def approve_or_reject(receipt_status, receipt_updated_by):
    if (receipt_status == 'A') or (receipt_status == 'R'):
        result = receipt_updated_by
    else:
        result = None
    return result


approve_or_reject_udf = udf(approve_or_reject, StringType())

receipt_staging_df = receipt_df.select('receipt_id',
                                       'invoice_no',
                                       'created_by',
                                       'updated_by',
                                       'spending_transaction_id',
                                       col('created_date').alias('receipt_upload_datetime'),
                                       to_date(col('created_date') - expr("INTERVAL 8 HOURS")).alias('receipt_upload_date').cast(DateType()),
                                       to_date(col('receipt_date')).alias('receipt_transaction_date').cast(DateType()),
                                       col('receipt_datetime').alias('receipt_transaction_datetime'),
                                       'status',
                                       'mall_id',
                                       'shop_id',
                                       col('payment_type_lang1').alias('payment_type'),
                                       col('original_amount').alias('receipt_amount'),
                                       'updated_date',
                                       'ocr_id') \
    .withColumn('approve_or_reject_by', approve_or_reject_udf('status', 'updated_by'))

spending_transaction_df = spending_transaction_df.select(col('spending_transaction_id').alias('mapping_spending_transaction_id'),
                                                         to_date(col('approval_date') - expr("INTERVAL 8 HOURS")).alias('approve_or_reject_date').cast(DateType()),
                                                         col('approval_date').alias('approve_or_reject_datetime'),
                                                         col('reject_reason_lang1').alias('reject_reason'),
                                                         'type',
                                                         'member_id',
                                                         'platform',
                                                         'channel',
                                                         'earned_points',
                                                         col('auto_approved').alias('ocr_auto_approved'))

receipt_status_detail_df = spark.createDataFrame(receipt_status_detail.items(), schema=StructType(fields=[StructField("mapping_status", StringType()),StructField("receipt_status_detail", StringType())]))
receipt_type_detail_df = spark.createDataFrame(receipt_type_detail.items(), schema=StructType(fields=[StructField("mapping_type", StringType()),StructField("receipt_type_detail", StringType())]))

# Transformation 7: Join all df together
spending_staging_df = receipt_staging_df.join(spending_transaction_df, receipt_staging_df.spending_transaction_id == spending_transaction_df.mapping_spending_transaction_id, how='left')\
                                        .filter("member_id != 'SHKP0519009'")

spending_staging_df.persist()

mall_mapping_df = mall_mapping_df.withColumnRenamed('mall_id', 'mapping_mall_id') \
                                .withColumnRenamed('district', 'mall_district') \
                                .withColumnRenamed('district_cs', 'mall_district_cs')
shop_df = shop_df.withColumnRenamed('shop_id', 'mapping_shop_id') \
                .withColumnRenamed('mall_id', 'mapping_mall_id') \
                .withColumnRenamed('property_id', 'mapping_property_id')

spending_staging_df = spending_staging_df.join(receipt_status_detail_df, spending_staging_df.status == receipt_status_detail_df.mapping_status, how='left') \
                                        .join(receipt_type_detail_df, spending_staging_df.type == receipt_type_detail_df.mapping_type, how='left') \
                                        .join(tmp_partner_mapping, spending_staging_df.spending_transaction_id == tmp_partner_mapping.mapping_spending_transaction_id, how='left') \
                                        .join(mall_mapping_df, spending_staging_df.mall_id == mall_mapping_df.mapping_mall_id, how='left') \
                                        .join(abnormal_log_df, abnormal_log_df.value == spending_staging_df.receipt_id, how='left')

# Transformation 8: tpdt_dw_spending final schema
dw_spending_2022_or_after = spending_staging_df.select('receipt_id',
                                                       'invoice_no',
                                                       'receipt_status_detail',
                                                       'created_by',
                                                       'receipt_upload_datetime',
                                                       'receipt_upload_date',
                                                       'receipt_transaction_datetime',
                                                       'receipt_transaction_date',
                                                       'spending_transaction_id',
                                                       'approve_or_reject_by',
                                                       'approve_or_reject_datetime',
                                                       'approve_or_reject_date',
                                                       'reject_reason',
                                                       'receipt_type_detail',
                                                       'mall_id',
                                                       'property_id',
                                                       'team',
                                                       'member_id',
                                                       'shop_id',
                                                       when(col('payment_type') == lit('BoC Pay'), lit('Boc Pay')).when(col('payment_type') == lit('UnionPay'), lit('Union Pay')).when(col('payment_type') == lit('Visa'), lit('VISA')).otherwise(col('payment_type')).alias('payment_type'),
                                                       'receipt_amount',
                                                       when(col('receipt_amount') < col('earned_points'), col('receipt_amount')).when((col('earned_points').isNull()) | (col('earned_points') == ''), 0).otherwise(col('earned_points')).alias('earned_points'),
                                                       when(col('value').isNotNull(), lit(1)).otherwise(lit(0)).alias('abnormal_case'),
                                                       'updated_date',
                                                       'platform',
                                                       when(col('platform') == 'api', col('channel')).otherwise(col('partner')).alias('partner'),
                                                       'ocr_auto_approved',
                                                       'ocr_id',
                                                       col('receipt_transaction_date').alias('PartitionKey'))\
                                                        .distinct()


tpdt_dw_spending_raw = dw_spending_2022_or_after.union(spending_before_delta_df).distinct()

tpdt_dw_spending_raw2 = tpdt_dw_spending_raw.join(member_df, tpdt_dw_spending_raw.member_id == member_df.mapping_member_id, how='left')\
                                            .join(shop_df, tpdt_dw_spending_raw.shop_id == shop_df.mapping_shop_id, how='left')

dw_spending_final = tpdt_dw_spending_raw2.select('receipt_id',
                                                 'invoice_no',
                                                 'receipt_status_detail',
                                                 'created_by',
                                                 'receipt_upload_datetime',
                                                 'receipt_upload_date',
                                                 'receipt_transaction_datetime',
                                                 'receipt_transaction_date',
                                                 'spending_transaction_id',
                                                 'approve_or_reject_by',
                                                 'approve_or_reject_datetime',
                                                 'approve_or_reject_date',
                                                 'reject_reason',
                                                 'receipt_type_detail',
                                                 'mall_id',
                                                 'property_id',
                                                 'team',
                                                 'member_id',
                                                 'member_status_detail',
                                                 'registration_date',
                                                 'gender',
                                                 'age',
                                                 'age_group',
                                                 'residence',
                                                 'district',
                                                 'district_cs',
                                                 'member_tier',
                                                 'shop_id',
                                                 'shop_name',
                                                 'lms_agreement_no',
                                                 'lms_trade_name',
                                                 'lms_standard_brand_name',
                                                 'lms_standard_trade_category',
                                                 'lms_standard_group',
                                                 col('lms_charge_area').cast(StringType()).alias('lms_charge_area'),
                                                 'payment_type',
                                                 'receipt_amount',
                                                 'earned_points',
                                                 'abnormal_case',
                                                 'updated_date',
                                                 'platform',
                                                 'partner',
                                                 'ocr_auto_approved',
                                                 'ocr_id',
                                                 'PartitionKey') \
                                                .distinct()

mall_spending = dw_spending_final.filter("mall_id not in (5004)")
partner_spending = dw_spending_final.filter("mall_id in (5004)")
## Data Transformation -----------------------------------------------------------------------------------------------------------------------------------------------------------

print("Saving Result into target destination...")
spending_output_path = "s3://tpdt-dw/tpdt_dw_spending/"
mall_spending.write.format('parquet').mode('overwrite').partitionBy("PartitionKey").option("header", True).save(spending_output_path)

partner_output_path = "s3://tpdt-dw/tpdt_partner_spending/"
partner_spending.write.format('parquet').mode('overwrite').partitionBy("PartitionKey").option("header", True).save(partner_output_path)
print(f"Result Saved in {output_path}...")


job.commit()

## Loading Result to S3 -----------------------------------------------------------------------------------------------------------------------------------------------------------





