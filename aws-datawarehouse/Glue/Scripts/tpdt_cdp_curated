import sys
import boto3
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from awsglue.dynamicframe import DynamicFrame
from datetime import datetime, date, time, timezone,timedelta 
from pyspark.sql.functions import *
from pyspark.sql.types import StringType
from pyspark.sql.types import IntegerType, FloatType
import pandas as pd
import numpy as np
import json
from datetime import datetime, date, time, timezone,timedelta 
from pyspark.sql.window import Window

args = getResolvedOptions(sys.argv, ['JOB_NAME', 'env'])
##Initialization
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)
 

##Input and Output Config
env = args['env']
if env == 'prod':
    db01="tpdt_01replica"
    db02="tpdt_02replica"
    db03="tpdt_03dw"
    db03sub="tpdt_03sub"
    output_path="s3://tpdt-cdp-dw/"
    staging_path="s3://tpdt-staging/"
    dimension_path="s3://tpdt-dimension/"
    secret_name = "tpdt_cdp_redshift"
    tmpdir = "s3://tpdt-data-from-cdp/redshift_tmpdir/"
    artifacts_s3 = "tpdt-artifacts"

else:
    db01="tpdt_01replica_"+env
    db03="tpdt_03dw_"+env
    db03sub="tpdt_03sub_"+env
    output_path="s3://tpdt-adobe-dw-"+env+"/"
    staging_path="s3://tpdt-staging-"+env+"/"
    dimension_path="s3://tpdt-dimension-"+env+"/"
    secret_name = f'tpdt_cdp_redshift_{env}'
    tmpdir = f"s3://tpdt-data-from-cdp-{env}/redshift_tmpdir/"
    artifacts_s3 = "tpdt-artifacts-{env}"


dimension_prefix = 'bi_dimension_'
prefix="shkpmalls_vip_"

client = boto3.client('secretsmanager')
response = client.get_secret_value(SecretId=secret_name)
secret = json.loads(response['SecretString'])
    
username = secret["username"]
pw = secret["password"]
host = secret["host"]
port = secret["port"]
db = secret["dbname"]

yesterday = datetime.now() - timedelta(1)
yesterday_string = datetime.strftime(yesterday, '%Y-%m-%d')

# UDFs
def inital_load(schema, table):
    # Redshift Connection Config
    my_conn_options = {  
        "url": f"jdbc:redshift://{host}:{port}/{db}",
        "dbtable": f'{schema}.{table}',
        "user": username,
        "password": pw,
        "customJdbcDriverS3Path": f"s3://{artifacts_s3}/Glue/PythonLibraries/redshift-jdbc42-2.1.0.1.jar",
        "customJdbcDriverClassName": "com.amazon.redshift.Driver",
        "sslMode": "DISABLED",
        "redshiftTmpDir": tmpdir
    }
    
    # Read Data from CDP Redshift
    source_dydf = glueContext.create_dynamic_frame.from_options(connection_type = "redshift", connection_options = my_conn_options)
    source_df = source_dydf.toDF()
    return source_df

def custom_load(query):
    # Read Data from CDP Redshift
    source_dydf = glueContext.read.format("jdbc")\
    .option("url",f"jdbc:redshift://{host}:{port}/{db}")\
    .option("user",username)\
    .option("password",pw)\
    .option("dbtable",query)\
    .load()
    return source_dydf
    
# tables to extract
# Extract Delivery_date---------------------------------------------------------------------------------------------------
# Table: global_customer_linkage -----------------------------------------------------------------------------------------
linkage_table = 'global_customer_linkage_vw'
linkage_schema = 'shkp_curated_ext_rls'
linkage_query="""(select hashmobileno, globalcustid, lobmemid_bu_tpt as member_id, 
case when lower(lobmemid_bu_yat) = 'yata member' then 1 else 0 end as YATA,
case when lower(lobmemid_bu_smt) = 'smt member' then 1 else 0 end as SMT,
case when lower(lobmemid_bu_kmb) = 'kmb member' then 1 else 0 end as KMB,
case when lower(lobmemid_bu_hy) = 'hy member' then 1 else 0 end as HY, 
case when lower(lobmemid_bu_ks) = 'ks member' then 1 else 0 end as KS, 
case when lower(lobmemid_bu_gr) = 'gr member' then 1 else 0 end as GR, 
createdttm,  lastupddttm from "shkp_curated_ext_rls".global_customer_linkage_vw 
) as t1"""

df = custom_load(linkage_query)
df.createOrReplaceTempView("customer_linkage")


# partner customer profile
yata_table = 'tpt_x_yat_lob_customer_profile_vw'
yata_schema = 'shkp_thepoint_vw'
yata = inital_load(yata_schema, yata_table)
yata1 = yata.withColumn('regdttm', to_timestamp(concat(col('regdttm'), lit(' 00:00:00')), 'yyyy-MM-dd HH:mm:ss'))
yata2 = yata1.groupBy('hashmobileno').agg(min('regdttm').alias('regdttm'))
yata2.createOrReplaceTempView("yata")


kmb_table = 'tpt_x_kmb_lob_customer_profile_vw'
kmb_schema = 'shkp_thepoint_vw'
kmb = inital_load(kmb_schema, kmb_table)
kmb1 = kmb.withColumn('regdttm', to_timestamp(col('regdttm'), 'yyyy-MM-dd HH:mm:ss'))
kmb2 = kmb1.groupBy('hashmobileno').agg(min('regdttm').alias('regdttm'))
kmb2.createOrReplaceTempView("kmb")

smt_table = 'tpt_x_smt_lob_customer_profile_vw'
smt_schema = 'shkp_thepoint_vw'
smt = inital_load(smt_schema, smt_table)
smt1 = smt.withColumn('regdttm', to_timestamp(col('regdttm'), 'yyyy-MM-dd HH:mm:ss'))
smt2 = smt1.groupBy('hashmobileno').agg(min('regdttm').alias('regdttm'))
smt2.createOrReplaceTempView("smt")

gr_table = 'tpt_x_gr_lob_customer_profile_vw'
gr_schema = 'shkp_thepoint_vw'
gr = inital_load(gr_schema, gr_table)
gr1 = gr.withColumn('regdttm', to_timestamp(col('regdttm'), 'yyyy-MM-dd HH:mm:ss'))
gr2 = gr1.groupBy('hashmobileno').agg(min('regdttm').alias('regdttm'))
gr2.createOrReplaceTempView("gr")

ks_table = 'tpt_x_ks_lob_customer_profile_vw'
ks_schema = 'shkp_thepoint_vw'
ks = inital_load(ks_schema, ks_table)
ks1 = ks.withColumn('regdttm', to_timestamp(col('regdttm'), 'yyyy-MM-dd HH:mm:ss'))
ks2 = ks1.groupBy('hashmobileno').agg(min('regdttm').alias('regdttm'))
ks2.createOrReplaceTempView("ks")

hy_table = 'tpt_x_hy_lob_customer_profile_vw'
hy_schema = 'shkp_thepoint_vw'
hy = inital_load(hy_schema, hy_table)
hy1 = hy.withColumn('regdttm', to_timestamp(col('regdttm'), 'yyyy-MM-dd HH:mm:ss'))
hy2 = hy1.groupBy('hashmobileno').agg(min('regdttm').alias('regdttm'))
hy2.createOrReplaceTempView("hy")

t_member = glueContext.create_dynamic_frame.from_catalog(database = db03sub, table_name = 'tpdt_staging_member', transformation_ctx = "member")
member_df = t_member.toDF().select('mapping_member_id', 'member_status_detail', 'registration_datetime')
member_df.createOrReplaceTempView("member")

'''
yata_df = spark.read.csv("s3://tpdt-data-from-cdp/yata_overlap/yata_overlap_member_id.csv", header='true', inferSchema='true', sep=',')
yata_df.createOrReplaceTempView("yata")
'''

# smt main sim
sim_table = 'tpt_x_smt_member_main_sim'
sim_schema = 'shkp_thepoint_vw'
sim = inital_load(sim_schema, sim_table)
sim.createOrReplaceTempView("sim")



overlap_df = spark.sql("""
Select Distinct 
t1.globalcustid,
t1.hashmobileno, 
t1.member_id, 
t2.member_status_detail,
t2.registration_datetime as thepoint_registration_datetime,
t1.YATA,
case when t3.hashmobileno is not null then 1 else 0 end as yata_active,
t3.regdttm as yata_registration_datetime,
t1.SMT, 
case when t5.hashmobileno is not null then 1 else 0 end as smt_active,
t5.regdttm as smt_registration_datetime,
case when t9.hashmobileno is not null then 1 else 0 end as smt_main_sim,
t9.plantype as smt_plan,
t1.KMB,
case when t4.hashmobileno is not null then 1 else 0 end as kmb_active,
t4.regdttm as kmb_registration_datetime,
t1.HY,
case when t7.hashmobileno is not null then 1 else 0 end as hy_active,
t7.regdttm as hy_registration_datetime,
t1.KS,
case when t6.hashmobileno is not null then 1 else 0 end as ks_active,
t6.regdttm as ks_registration_datetime,
t1.GR,
case when t8.hashmobileno is not null then 1 else 0 end as gr_active,
t8.regdttm as gr_registration_datetime,
t1.createdttm as cdp_created_datetime,  
t1.lastupddttm as cdp_updated_datetime
from customer_linkage t1
left join member t2 on t1.member_id = t2.mapping_member_id
left join yata t3 on t1.hashmobileno = t3.hashmobileno and t1.YATA = 1
left join kmb t4 on t1.hashmobileno = t4.hashmobileno and t1.KMB = 1
left join smt t5 on t1.hashmobileno = t5.hashmobileno and t1.SMT = 1
left join ks t6 on t1.hashmobileno = t6.hashmobileno and t1.KS = 1
left join hy t7 on t1.hashmobileno = t7.hashmobileno and t1.HY = 1
left join gr t8 on t1.hashmobileno = t8.hashmobileno and t1.GR = 1
left join sim t9 on t1.hashmobileno = t9.hashmobileno and t1.SMT = 1
""")

overlap_output_path = f"s3://tpdt-cdp-dw/member_overlap/"
overlap_df.write.format('parquet').mode('overwrite').option("header",True).save(overlap_output_path)


# Table: lob_customer_linkage -----------------------------------------------------------------------------------------
attribute_table = 'global_customer_attribute_vw'
attribute_schema = 'shkp_curated_ext_rls'

attribute_df = inital_load(attribute_schema, attribute_table)
attribute_df = attribute_df.withColumn('PartitionKey', col('cat'))\
                           .withColumn('createdttm', to_date(col('createdttm').substr(1,10),'yyyy-MM-dd'))\
                           .withColumn('lastupddttm', to_date(col('lastupddttm').substr(1,10),'yyyy-MM-dd'))\
                           .withColumn('createDate', to_date(col('createDate').substr(1,10),'yyyy-MM-dd'))\
                           .withColumn('endDate', to_date(col('endDate').substr(1,10),'yyyy-MM-dd'))
 

attribute_output_path=f"s3://tpdt-cdp-dw/customer_attribute/"
attribute_df.write.format('parquet').mode('overwrite').partitionBy("PartitionKey").option("header",True).save(attribute_output_path)

# Table: rfm -----------------------------------------------------------------------------------------
def rfm():
    rfm_table = 'lob_rfm_vw'
    rfm_schema = 'shkp_curated_ext_rls'
    
    rfm_df = inital_load(rfm_schema, rfm_table)
    rfm_df = rfm_df.withColumn('recency', col('recency').cast(IntegerType()))\
                   .withColumn('frequency', col('frequency').cast(IntegerType()))\
                   .withColumn('monetary', col('monetary').cast(FloatType()))\
                   .withColumn('monetary_rank', col('monetary_rank').cast(FloatType()))\
                   .withColumn('frequency_rank', col('frequency_rank').cast(FloatType()))\
                   .withColumn('monetary_quintile', col('monetary_quintile').cast(IntegerType()))\
                   .withColumn('frequency_quintile', col('frequency_quintile').cast(IntegerType()))\
                   .withColumn('fm_label', col('fm_label').cast(IntegerType()))\
                   .withColumn('is_lifestyler', col('is_lifestyler').cast(IntegerType()))\
                   .withColumn('p_days', col('p_days').cast(IntegerType()))\
                   .withColumn('ref_date', to_date(col('ref_date').substr(1,10),'yyyy-MM-dd'))\
                   .withColumn('PartitionKey', col('ref_date'))
        
    rfm_output_path=f"s3://tpdt-cdp-dw/rfm/"
    rfm_df.write.format('parquet').mode('overwrite').partitionBy("PartitionKey").option("header",True).save(rfm_output_path)

if yesterday_string[-2:]=='15':
    rfm()
else:
    pass


# Table: brand_by_carplate -----------------------------------------------------------------------------------------
brand_by_carplate_table = 'parker_profile_vw'
brand_by_carplate_schema = 'shkp_thepoint_vw'

brand_by_carplate_df = inital_load(brand_by_carplate_schema, brand_by_carplate_table)
brand_by_carplate_df = brand_by_carplate_df.withColumn('brand', trim(upper(col('brand'))))\
                           .withColumn('car_plate', trim(upper(col('car_plate'))))\
                           .withColumn('last_car_brand_recognize_date', to_date(col('last_car_brand_recognize_date'),'yyyyMMdd'))\
                           .drop('member_id')\
                           .distinct()
 

brand_by_carplate_output_path=f"s3://tpdt-parking/brand_by_carplate/"
brand_by_carplate_df.write.format('parquet').mode('overwrite').option("header",True).save(brand_by_carplate_output_path)


